# Import the Imputer module

from sklearn.preprocessing import Imputer

from sklearn.svm import SVC


# Setup the Imputation transformer: imp

imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)


# Instantiate the SVC classifier: clf

clf = SVC()


# Setup the pipeline with the required steps: steps

steps = [('imputation', imp),
('SVM', clf)]

# Import necessary modules

from sklearn.preprocessing import Imputer

from sklearn.pipeline import Pipeline

from sklearn.svm import SVC


# Setup the pipeline steps: steps
s
teps = [('imputation', Imputer(missing_values='NaN', strategy='most_frequent', axis=0)),
('SVM', SVC())]


# Create the pipeline: pipeline

pipeline = Pipeline(steps)


# Create training and test sets

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 42)


# Fit the pipeline to the train set

pipeline.fit(X_train,y_train)


# Predict the labels of the test set

y_pred = pipeline.predict(X_test)


# Compute metrics

print(classification_report(y_test,y_pred))

# Import the necessary modules

from sklearn.preprocessing import StandardScaler

from sklearn.pipeline import Pipeline


# Setup the pipeline steps: steps

steps = [('scaler', StandardScaler()),
        ('knn', KNeighborsClassifier())]
        

# Create the pipeline: pipeline

pipeline = Pipeline(steps)


# Create train and test sets

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3,random_state = 42)


# Fit the pipeline to the training set: knn_scaled

knn_scaled = pipeline.fit(X_train,y_train)


# Instantiate and fit a k-NN classifier to the unscaled data

knn_unscaled = KNeighborsClassifier().fit(X_train, y_train)


# Compute and print metrics

print('Accuracy with Scaling: {}'.format(knn_scaled.score(X_test,y_test)))

print('Accuracy without Scaling: {}'.format(knn_unscaled.score(X_test,y_test)))


# Setup the pipeline

steps = [('scaler', StandardScaler()),
         ('SVM', SVC())]


pipeline = Pipeline(steps)


# Specify the hyperparameter space

parameters = {'SVM__C':[1, 10, 100],'SVM__gamma':[0.1, 0.01]}


# Create train and test sets

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2,random_state = 21)


# Instantiate the GridSearchCV object: cv

cv = GridSearchCV(pipeline,parameters,cv = 3)


# Fit to the training set

cv.fit(X_train,y_train)


# Predict the labels of the test set: y_pred

y_pred = cv.predict(X_test)


# Compute and print metrics

print("Accuracy: {}".format(cv.score(X_test, y_test)))

print(classification_report(y_test, y_pred))

print("Tuned Model Parameters: {}".format(cv.best_params_))


# Setup the pipeline steps: steps
steps = [('imputation', Imputer(missing_values='NaN', strategy='mean', axis=0)),
         ('scaler', StandardScaler()),
         ('elasticnet', ElasticNet())]
         
# Create the pipeline: pipeline
pipeline = Pipeline(steps)

# Specify the hyperparameter space
parameters = {'elasticnet__l1_ratio':np.linspace(0,1,30)}

# Create train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)

# Create the GridSearchCV object: gm_cv
gm_cv = GridSearchCV(pipeline, parameters)

# Fit to the training set
gm_cv.fit(X_train, y_train)

# Compute and print the metrics
r2 = gm_cv.score(X_test, y_test)
print("Tuned ElasticNet Alpha: {}".format(gm_cv.best_params_))
print("Tuned ElasticNet R squared: {}".format(r2))

